{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC6dQxs0guiE"
      },
      "source": [
        "### Installation\n",
        "Install LLM framework packages for OpenAI, Gemini, Fireworks AI, and Anthropic (Claude) models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q langchain-openai       # LLM framework for OpenAI\n",
        "%pip install -q langchain-core\n",
        "%pip install -q langchain-google-genai # LLM framework for Gemini\n",
        "%pip install -q langchain-fireworks   # LLM framework for Fireworks AI (open-source models)\n",
        "%pip install -q langchain_google_vertexai anthropic[vertex] # LLM framework for Anthropic (Claude models)\n",
        "%pip install -q langchain\n",
        "%pip install -q openai\n",
        "%pip install -q langchain-community\n",
        "%pip install -q Langchainhub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlFmgViYFA_C",
        "outputId": "8153da47-a3ba-457f-8509-0c542ebf2bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.8/193.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.2/100.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVT8JsJMgv7_"
      },
      "source": [
        "### API Keys\n",
        "Set API keys for LLM providers (OpenAI, Gemini, Fireworks, Anthropic via VertexAI)\n",
        "\n",
        "***Note: Replace placeholder keys with your own keys***\n",
        "\n",
        "For VertexAI, requires a service account JSON key file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qizOSABDMvQ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# OpenAI\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Placeholder\"\n",
        "\n",
        "# Gemini\n",
        "import google.generativeai as genai\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"Placeholder\"\n",
        "\n",
        "# Fireworks\n",
        "import fireworks.client\n",
        "os.environ[\"FIREWORKS_API_KEY\"] = \"Placeholder\"\n",
        "\n",
        "# Anthropic (from Vertex AI)\n",
        "import json\n",
        "anthropic_key = {\n",
        "    \"Placeholder\"\n",
        "    }\n",
        "with open('anthropic_key.json', 'w') as f:\n",
        "    json.dump(anthropic_key, f, indent=4)\n",
        "from google.oauth2 import service_account\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"Placeholder\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im-ODqKdgxPz"
      },
      "source": [
        "### Libraries\n",
        "Imports for multi-LLM setup (OpenAI, Gemini, Fireworks, Anthropic) with LangChain core components\n",
        "\n",
        "Includes initialization for VertexAI (Anthropic Claude)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGgFz4FPDZ4o"
      },
      "outputs": [],
      "source": [
        "# OpenAI\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Gemini\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Fireworks\n",
        "from langchain_fireworks import ChatFireworks\n",
        "\n",
        "# Anthropic (from Vertex AI)\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"Placeholder\"\n",
        "project = \"Placeholder\"\n",
        "location = \"Placeholder\"\n",
        "import vertexai\n",
        "vertexai.init(project=project, location=location)\n",
        "from langchain_google_vertexai.model_garden import ChatAnthropicVertex\n",
        "\n",
        "# Lanchain (chain)\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krRS8jhggzyP"
      },
      "source": [
        "### LLM Models\n",
        "Initialize multi-LLM chat models for different providers:\n",
        "- OpenAI: GPT-4.1 Mini\n",
        "- Google: Gemini 2.0 Flash\n",
        "- Fireworks: Llama 3.3 70B, Qwen3 30B-A3B, DeepSeek V3\n",
        "- Anthropic: Claude 3.5 Haiku (via VertexAI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCV5l9WUY21G"
      },
      "outputs": [],
      "source": [
        "llm_ChatGPT = ChatOpenAI(model = \"gpt-4.1-mini\")\n",
        "\n",
        "llm_Gemini = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash\")\n",
        "\n",
        "llm_Llama = ChatFireworks(model = \"accounts/fireworks/models/llama-v3p3-70b-instruct\") #Llama 3.3 70B Instruct\n",
        "\n",
        "llm_Qwen = ChatFireworks(model = \"accounts/fireworks/models/qwen3-235b-a22b\") #Qwen3 235B-A22B\n",
        "\n",
        "llm_DeepSeek = ChatFireworks(model = \"accounts/fireworks/models/deepseek-v3\") #DeepSeek V3\n",
        "\n",
        "llm_Claude = ChatAnthropicVertex(model_name=\"claude-3-5-haiku@20241022\",project=project,location=location) # Claude 3.5 Haiku\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkd_mLRqg1bB"
      },
      "source": [
        "### Prompt\n",
        "Purpose: Forces LLM to output ONLY the letter corresponding to the correct answer choice\n",
        "Behavior:\n",
        "  1. Performs analysis of context and choices\n",
        "  2. Returns strictly formatted single-letter response (A/B/C/D)\n",
        "  3. Explicitly prohibits explanations or additional text\n",
        "\n",
        "Format Enforcement:\n",
        "- Uses clear instruction boundaries (### Instruction: / ### Response Format:)\n",
        "- Provides concrete example of expected input/output\n",
        "- Emphasizes strict compliance through wording (\"only\", \"strictly avoid\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"\n",
        "### Instruction:\n",
        "You are a reasoning assistant.\n",
        "\n",
        "1. Analyze the given context thoroughly.\n",
        "2. Identify the best option from the provided choices.\n",
        "\n",
        "### Response Format:\n",
        "- Provide **only** the letter corresponding to the correct answer (e.g., A, B, C, or D).\n",
        "- Strictly avoid additional text, explanations, or context in your response.\n",
        "\n",
        "EXAMPLE INPUT\n",
        " Dolores Huerta’s advocacy on behalf of farmworkers was rooted in her experience as a schoolteacher in Stockton,\n",
        " California, in the early 1950s. Hoping to help her students and their families outside the ______ Huerta left teaching to\n",
        " start the Stockton chapter of the Community Service Organization, a group focused on the needs of local farmworkers.\n",
        "\n",
        " Which choice completes the text so that it conforms to the conventions of Standard English?\n",
        " A. classroom.\n",
        " B. classroom;\n",
        " C. classroom,\n",
        " D. classroom\n",
        "\n",
        " EXAMPLE OUTPUT\n",
        " C\n",
        "\n",
        "{input}\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "9gTREsaW7TAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZiKmFDHIjT2"
      },
      "source": [
        "## Import questions\n",
        "SAT Question Data Loader\n",
        "Imports and formats SAT practice questions from a GitHub repository.\n",
        "\n",
        "Data Structure:\n",
        "- Loads pipe-separated (#) CSV data from GitHub raw URL\n",
        "- Contains question metadata (ID, Difficulty, Type of Question/Skill)\n",
        "- Includes question text, 4 multiple-choice options (A-D), and correct answer\n",
        "- Formats into pandas DataFrame with descriptive column names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "hB0j64SUIklz",
        "outputId": "f1979dd0-c9f9-4753-9117-295c39f162de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         ID Difficulty            Type of Question  \\\n",
              "0  87aa7bab     medium   central ideas and details   \n",
              "1  d748c3fd     medium                  inferences   \n",
              "2  22e4d633     medium         command of evidence   \n",
              "3  359902ae     medium            words in context   \n",
              "4  2af2016f     medium  text structure and purpose   \n",
              "\n",
              "                                            Question  \\\n",
              "0  A common assumption among art historians is th...   \n",
              "1  In her 2021 article “Throwaway History: Toward...   \n",
              "2  Although many transposons, DNA sequences that ...   \n",
              "3  The following text is adapted from Nathaniel H...   \n",
              "4  A study by Dr. Paul Hanel and colleagues concl...   \n",
              "\n",
              "                                            Option A  \\\n",
              "0  A. Factors other than the rise of photography ...   \n",
              "1  A. demonstrate the difficulties faced by conte...   \n",
              "2  A. The LINE transposon in O. vulgaris and O. b...   \n",
              "3                                        A. A lonely   \n",
              "4  A. To describe a widely held belief and how a ...   \n",
              "\n",
              "                                            Option B  \\\n",
              "0  B. Although portrait miniatures became less co...   \n",
              "1  B. represent the challenge of incorporating ex...   \n",
              "2  B. The human genome contains multiple transpos...   \n",
              "3                                  B. A disagreeable   \n",
              "4  B. To argue that researchers were surprised by...   \n",
              "\n",
              "                                            Option C  \\\n",
              "0  C. The popularity of the portrait miniature li...   \n",
              "1  C. lend support to arguments by historians and...   \n",
              "2  C. A consistent number of copies of LINE trans...   \n",
              "3                                   C. An acceptable   \n",
              "4  C. To suggest ways to improve a certain study’...   \n",
              "\n",
              "                                            Option D Correct Answer  \n",
              "0  D. As demand for portrait miniatures decreased...              a  \n",
              "1  D. illustrate both the relatively low scholarl...              d  \n",
              "2  D. O. vulgaris and O. bimaculoides have smalle...              a  \n",
              "3                                D. An extraordinary              d  \n",
              "4  D. To explain a study’s conclusion and how a r...              d  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-489ce7dc-6f29-4aa0-874e-df8a30f0a894\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Difficulty</th>\n",
              "      <th>Type of Question</th>\n",
              "      <th>Question</th>\n",
              "      <th>Option A</th>\n",
              "      <th>Option B</th>\n",
              "      <th>Option C</th>\n",
              "      <th>Option D</th>\n",
              "      <th>Correct Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>87aa7bab</td>\n",
              "      <td>medium</td>\n",
              "      <td>central ideas and details</td>\n",
              "      <td>A common assumption among art historians is th...</td>\n",
              "      <td>A. Factors other than the rise of photography ...</td>\n",
              "      <td>B. Although portrait miniatures became less co...</td>\n",
              "      <td>C. The popularity of the portrait miniature li...</td>\n",
              "      <td>D. As demand for portrait miniatures decreased...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d748c3fd</td>\n",
              "      <td>medium</td>\n",
              "      <td>inferences</td>\n",
              "      <td>In her 2021 article “Throwaway History: Toward...</td>\n",
              "      <td>A. demonstrate the difficulties faced by conte...</td>\n",
              "      <td>B. represent the challenge of incorporating ex...</td>\n",
              "      <td>C. lend support to arguments by historians and...</td>\n",
              "      <td>D. illustrate both the relatively low scholarl...</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22e4d633</td>\n",
              "      <td>medium</td>\n",
              "      <td>command of evidence</td>\n",
              "      <td>Although many transposons, DNA sequences that ...</td>\n",
              "      <td>A. The LINE transposon in O. vulgaris and O. b...</td>\n",
              "      <td>B. The human genome contains multiple transpos...</td>\n",
              "      <td>C. A consistent number of copies of LINE trans...</td>\n",
              "      <td>D. O. vulgaris and O. bimaculoides have smalle...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>359902ae</td>\n",
              "      <td>medium</td>\n",
              "      <td>words in context</td>\n",
              "      <td>The following text is adapted from Nathaniel H...</td>\n",
              "      <td>A. A lonely</td>\n",
              "      <td>B. A disagreeable</td>\n",
              "      <td>C. An acceptable</td>\n",
              "      <td>D. An extraordinary</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2af2016f</td>\n",
              "      <td>medium</td>\n",
              "      <td>text structure and purpose</td>\n",
              "      <td>A study by Dr. Paul Hanel and colleagues concl...</td>\n",
              "      <td>A. To describe a widely held belief and how a ...</td>\n",
              "      <td>B. To argue that researchers were surprised by...</td>\n",
              "      <td>C. To suggest ways to improve a certain study’...</td>\n",
              "      <td>D. To explain a study’s conclusion and how a r...</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-489ce7dc-6f29-4aa0-874e-df8a30f0a894')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-489ce7dc-6f29-4aa0-874e-df8a30f0a894 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-489ce7dc-6f29-4aa0-874e-df8a30f0a894');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-edca4479-79ec-4487-abf5-cf8091a969d5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-edca4479-79ec-4487-abf5-cf8091a969d5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-edca4479-79ec-4487-abf5-cf8091a969d5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sat_questions",
              "summary": "{\n  \"name\": \"sat_questions\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 86,\n        \"samples\": [\n          \"d4732483\",\n          \"87aa7bab\",\n          \"45a109a3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Difficulty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"medium\",\n          \"hard\",\n          \"easy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type of Question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"boundaries\",\n          \"inferences\",\n          \"cross-text connections\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 87,\n        \"samples\": [\n          \"Studying late nineteenth- and early twentieth-century artifacts from an agricultural and domestic site in Texas, archaeologist Ayana O. Flewellen found that Black women employed as farm workers utilized hook-and-eye closures to fasten their clothes at the waist, giving themselves a silhouette similar to the one that was popular in contemporary fashion and typically achieved through more restrictive garments such as corsets. Flewellen argues that this sartorial practice shows that these women balanced hegemonic ideals of femininity with the requirements of their physically demanding occupation. Which choice best states the main purpose of the text?\",\n          \"A common assumption among art historians is that the invention of photography in the mid-nineteenth century displaced the painted portrait in the public consciousness. The diminishing popularity of the portrait miniature, which coincided with the rise of photography, seems to support this claim. However, photography\\u2019s impact on the portrait miniature may be overstated. Although records from art exhibitions in the Netherlands from 1820 to 1892 show a decrease in the number of both full-sized and miniature portraits submitted, this trend was established before the invention of photography. Based on the text, what can be concluded about the diminishing popularity of the portrait miniature in the nineteenth century?\",\n          \"While researching a topic, a student has taken the following notes: The Philadelphia and Lancaster Turnpike was a road built between 1792 and 1794. It was the first private turnpike in the United States. It connected the cities of Philadelphia and Lancaster in the state of Pennsylvania. It was sixty-two miles long. The student wants to emphasize the distance covered by the Philadelphia and Lancaster Turnpike. Which choice most effectively uses relevant information from the notes to accomplish this goal?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Option A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"prove financially successful for some musicians but disappointing for others.\",\n          \"A. None of the sea stars climbed to the tops of the tanks, but sea stars in the tank with only seawater moved around the bottom of the tank more than sea stars in the other tank did.\",\n          \"the researchers theorize that moths, mistaking nighttime lights for the Sun, continually try to reorient their bodies while flying near such lights.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Option B\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"hold greater financial appeal for bands than for individual musicians.\",\n          \"B. Sea stars in the tank with only seawater climbed to the top of the tank, but sea stars in the other tank stopped climbing just below the layer of fresh water.\",\n          \"the researchers\\u2019 theory is that moths mistake nighttime lights for the Sun, continually trying to reorient their bodies while flying near such lights.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Option C\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"cause most musicians who use the model to lower the suggested prices of their songs and albums over time.\",\n          \"C. Both groups of sea stars climbed to the tops of the tanks, but sea stars in the tank with only seawater climbed more slowly than sea stars in the other tank did.\",\n          \"moths mistake nighttime lights for the Sun and continually try to reorient their bodies while flying near such lights, the researchers theorize.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Option D\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"more strongly reflect differences in certain musicians\\u2019 popularity than traditional pricing models do.\",\n          \"D. Sea stars in the tank with only seawater mostly stayed near the bottom of the tank, but sea stars in the other tank climbed into the layer of fresh water.\",\n          \"moths continually try to reorient their bodies while flying near nighttime lights, the researchers theorize, mistaking such lights for the Sun.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct Answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"d\",\n          \"c\",\n          \"a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# GitHub raw URL containing pipe-separated SAT question data\n",
        "url = \"https://raw.githubusercontent.com/1082098-LWSD/SAT-question-evaluation/main/SATQuestions\"\n",
        "\n",
        "# Import data with custom separator and no header\n",
        "sat_questions = pd.read_csv(\n",
        "    url,\n",
        "    sep=\"#\",            # Custom pipe separator\n",
        "    engine=\"python\",        # Required for custom separators\n",
        "    header=None           # No existing header row\n",
        ")\n",
        "\n",
        "# Apply human-readable column names\n",
        "sat_questions.columns = [\n",
        "    \"ID\",             # Unique question identifier\n",
        "    \"Difficulty\",         # Question difficulty level\n",
        "    \"Type of Question\",     # Question category/type\n",
        "    \"Question\",          # Question text\n",
        "    \"Option A\",         # Multiple choice option A\n",
        "    \"Option B\",         # Multiple choice option B\n",
        "    \"Option C\",         # Multiple choice option C\n",
        "    \"Option D\",         # Multiple choice option D\n",
        "    \"Correct Answer\"       # Letter of correct option (A-D)\n",
        "]\n",
        "\n",
        "# Preview the structured data\n",
        "sat_questions.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constructing Query\n",
        "Construct standardized query strings for LLM processing by combining:\n",
        "1. Question context\n",
        "2. All multiple-choice options (A-D)\n",
        "\n",
        "Format:\n",
        "\n",
        "Context and Question: [question text]\n",
        "\n",
        "Options:\n",
        "\n",
        "[Option A]\n",
        "\n",
        "[Option B]\n",
        "\n",
        "[Option C]\n",
        "\n",
        "[Option D]\n"
      ],
      "metadata": {
        "id": "xKARqVvcJ8Dl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzKvJFHyIwJ0"
      },
      "outputs": [],
      "source": [
        "sat_questions['Query'] = (\n",
        "    \"Context and Question: \" + sat_questions['Question'] + \"\\n\"\n",
        "    + \"Options: \"\n",
        "    + sat_questions['Option A'] + \"\\n\"\n",
        "    + sat_questions['Option B'] + \"\\n\"\n",
        "    + sat_questions['Option C'] + \"\\n\"\n",
        "    + sat_questions['Option D']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAT Question Evaluation System\n",
        "\n",
        "This script evaluates a singular LLM's performance on SAT-style questions across multiple dimensions:\n",
        "- Difficulty levels (easy/medium/hard)\n",
        "- Question types (Writing, Reading, Math)\n",
        "- Skill subdivisions (e.g., Boundaries, Command of Evidence)\n",
        "\n",
        "Key Features:\n",
        "1. Multi-run evaluation: Each question is processed 3 times to assess consistency\n",
        "2. Error handling: Automatic retries with delay for failed attempts\n",
        "3. Comprehensive analysis:\n",
        "   - Accuracy by difficulty and question type\n",
        "   - Response variability (consistency across runs)\n",
        "   - Skill subdivision breakdowns\n",
        "4. Data preservation: Saves raw results and aggregated metrics\n",
        "\n",
        "Output Includes:\n",
        "1. Accuracy pivot tables (% correct by subdivision/difficulty)\n",
        "2. Count tables (question distribution)\n",
        "3. Full accuracy analysis (all categories combined)\n",
        "4. CSV exports of raw results and aggregated metrics\n",
        "\n",
        "Usage Notes:\n",
        "- Configure model_name and model at start\n",
        "- Set questions_per_difficulty for sampling\n",
        "- Adjust max_retries and retry_delay as needed"
      ],
      "metadata": {
        "id": "oGppGHzzI9gI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Define the model to evaluate\n",
        "model_name = \"llm_ChatGPT\" # Model identifier for reporting\n",
        "model = llm_ChatGPT # Actual model instance\n",
        "\n",
        "# Define all possible categories\n",
        "all_difficulties = ['easy', 'medium', 'hard']\n",
        "skill_subdivisions = {\n",
        "    'Standard English Conventions': [\"boundaries\", \"form, structure, and sense\"],\n",
        "    'Information and Ideas': [\"central ideas and details\", \"inferences\", \"command of evidence\"],\n",
        "    'Craft and Structure': [\"words in context\", \"text structure and purpose\", \"cross-text connections\"],\n",
        "    'Expression of Ideas': [\"rhetorical synthesis\", \"transitions\"]\n",
        "}\n",
        "all_subdivisions = list(skill_subdivisions.keys())\n",
        "all_skills = [skill for sublist in skill_subdivisions.values() for skill in sublist]\n",
        "\n",
        "# Initialize an empty list to store results\n",
        "results = []\n",
        "\n",
        "# Number of questions to evaluate per difficulty level\n",
        "questions_per_difficulty = 30\n",
        "max_retries = 3  # Maximum number of retry attempts\n",
        "retry_delay = 5   # Seconds to wait between retries\n",
        "\n",
        "# Loop through each question in the DataFrame\n",
        "for _, row in sat_questions.iterrows():\n",
        "    if len(results) >= questions_per_difficulty * 3:\n",
        "        break\n",
        "\n",
        "    query = row['Query']\n",
        "    correct_answer = row['Correct Answer']\n",
        "    difficulty = row['Difficulty']\n",
        "    skill = row['Type of Question']\n",
        "\n",
        "    model_responses = []\n",
        "    retry_count = 0\n",
        "\n",
        "    # Run the model 3 times for the current query\n",
        "    for i in range(3):\n",
        "        while retry_count < max_retries:\n",
        "            try:\n",
        "                chain = (\n",
        "                    RunnablePassthrough.assign(context=(lambda x: x[\"input\"]))\n",
        "                    | prompt\n",
        "                    | model\n",
        "                    | StrOutputParser()\n",
        "                )\n",
        "                result = chain.invoke({\n",
        "                    'input': query,\n",
        "                    'temperature': 0,\n",
        "                    'max_tokens': 2,\n",
        "                })\n",
        "                model_responses.append(result.strip().upper())\n",
        "                break  # Success - exit retry loop\n",
        "            except Exception as e:  # Catch all exceptions\n",
        "                retry_count += 1\n",
        "                if retry_count >= max_retries:\n",
        "                    model_responses.append(\"ERROR\")\n",
        "                    print(f\"Failed to get response for query after {max_retries} attempts: {query}\")\n",
        "                    print(f\"Error: {str(e)}\")\n",
        "                else:\n",
        "                    print(f\"Retry {retry_count} for query: {query}\")\n",
        "                    time.sleep(retry_delay)\n",
        "\n",
        "    # Filter out error responses before calculating mode\n",
        "    valid_responses = [r for r in model_responses if r != \"ERROR\"]\n",
        "    if not valid_responses:\n",
        "        most_frequent_answer = \"ERROR\"\n",
        "        variability = 0\n",
        "    else:\n",
        "        most_frequent_answer = Counter(valid_responses).most_common(1)[0][0]\n",
        "        variability = len(set(valid_responses))\n",
        "\n",
        "    normalized_correct_answer = str(correct_answer).strip().upper()\n",
        "    is_correct = most_frequent_answer == normalized_correct_answer if most_frequent_answer != \"ERROR\" else False\n",
        "\n",
        "    subdivision = next((subdiv for subdiv, skills in skill_subdivisions.items()\n",
        "                      if skill in skills), None)\n",
        "\n",
        "    results.append({\n",
        "        'Query': query,\n",
        "        'Difficulty': difficulty,\n",
        "        'Type of Question': skill,\n",
        "        'Subdivision': subdivision,\n",
        "        'Correct Answer': normalized_correct_answer,\n",
        "        'Model Mode Answer': most_frequent_answer,\n",
        "        'Is Correct': is_correct,\n",
        "        'Variability': variability,\n",
        "        'Responses': model_responses,\n",
        "        'Attempts': 3 - model_responses.count(\"ERROR\")\n",
        "    })\n",
        "\n",
        "# Convert results into DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Create two-way tables for accuracy and counts\n",
        "accuracy_pivot = results_df.pivot_table(\n",
        "    index='Subdivision',\n",
        "    columns='Difficulty',\n",
        "    values='Is Correct',\n",
        "    aggfunc=lambda x: (x.sum() / len(x)) * 100,\n",
        "    fill_value=0\n",
        ").round(1)\n",
        "\n",
        "count_pivot = results_df.pivot_table(\n",
        "    index='Subdivision',\n",
        "    columns='Difficulty',\n",
        "    values='Is Correct',\n",
        "    aggfunc='count',\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "# Add totals\n",
        "accuracy_pivot['Total'] = results_df.groupby('Subdivision')['Is Correct'].mean() * 100\n",
        "count_pivot['Total'] = results_df.groupby('Subdivision')['Is Correct'].count()\n",
        "\n",
        "accuracy_pivot.loc['Total'] = results_df.groupby('Difficulty')['Is Correct'].mean() * 100\n",
        "count_pivot.loc['Total'] = results_df.groupby('Difficulty')['Is Correct'].count()\n",
        "\n",
        "# Format tables - using map() instead of applymap()\n",
        "accuracy_pivot = accuracy_pivot.map(lambda x: f\"{x}%\" if pd.notna(x) else \"0%\")\n",
        "count_pivot = count_pivot.map(lambda x: f\"{int(x)}\" if pd.notna(x) else \"0\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Accuracy by Subdivision and Difficulty (% correct):\")\n",
        "print(\"=\"*60)\n",
        "print(accuracy_pivot)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Number of Questions by Subdivision and Difficulty:\")\n",
        "print(\"=\"*60)\n",
        "print(count_pivot)\n",
        "\n",
        "# Create template DataFrames with all categories\n",
        "def create_template_df(categories, name_col):\n",
        "    return pd.DataFrame({name_col: categories,\n",
        "                        'total_questions': 0,\n",
        "                        'correct_answers': 0,\n",
        "                        'average_variability': 0.0})\n",
        "\n",
        "difficulty_template = create_template_df(all_difficulties, 'Difficulty')\n",
        "subdivision_template = create_template_df(all_subdivisions, 'Subdivision')\n",
        "skill_template = create_template_df(all_skills, 'Type of Question')\n",
        "\n",
        "# Calculate actual results\n",
        "def calculate_accuracy(df, group_col):\n",
        "    if group_col in df.columns:\n",
        "        actual = df.groupby(group_col).agg(\n",
        "            total_questions=('Is Correct', 'size'),\n",
        "            correct_answers=('Is Correct', 'sum'),\n",
        "            average_variability=('Variability', 'mean')\n",
        "        ).reset_index()\n",
        "        actual.columns = [group_col, 'total_questions', 'correct_answers', 'average_variability']\n",
        "        return actual\n",
        "    return None\n",
        "\n",
        "# Merge actual results with templates\n",
        "def merge_with_template(actual, template, name_col):\n",
        "    if actual is not None:\n",
        "        merged = template.merge(actual, on=name_col, how='left', suffixes=('_template', ''))\n",
        "        for col in ['total_questions', 'correct_answers', 'average_variability']:\n",
        "            merged[col] = merged[col+'_template'].where(pd.isna(merged[col]), merged[col])\n",
        "        return merged.drop(columns=[col+'_template' for col in ['total_questions', 'correct_answers', 'average_variability']])\n",
        "    return template\n",
        "\n",
        "difficulty_accuracy = merge_with_template(\n",
        "    calculate_accuracy(results_df, 'Difficulty'),\n",
        "    difficulty_template,\n",
        "    'Difficulty'\n",
        ")\n",
        "\n",
        "subdivision_accuracy = merge_with_template(\n",
        "    calculate_accuracy(results_df, 'Subdivision'),\n",
        "    subdivision_template,\n",
        "    'Subdivision'\n",
        ")\n",
        "\n",
        "skill_accuracy = merge_with_template(\n",
        "    calculate_accuracy(results_df, 'Type of Question'),\n",
        "    skill_template,\n",
        "    'Type of Question'\n",
        ")\n",
        "\n",
        "# Calculate accuracy percentage\n",
        "for df in [difficulty_accuracy, subdivision_accuracy, skill_accuracy]:\n",
        "    df['Accuracy (%)'] = (df['correct_answers'] / df['total_questions'].replace(0, 1)) * 100\n",
        "    df['Accuracy (%)'] = df['Accuracy (%)'].fillna(0)\n",
        "\n",
        "# Combine all accuracy tables\n",
        "full_accuracy_table = pd.concat([\n",
        "    difficulty_accuracy.assign(Category='Difficulty', Name=difficulty_accuracy['Difficulty']),\n",
        "    subdivision_accuracy.assign(Category='Subdivision', Name=subdivision_accuracy['Subdivision']),\n",
        "    skill_accuracy.assign(Category='Type of Question', Name=skill_accuracy['Type of Question'])\n",
        "])[['Category', 'Name', 'total_questions', 'correct_answers', 'Accuracy (%)', 'average_variability']]\n",
        "\n",
        "# Display the full accuracy table\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Full Accuracy Analysis:\")\n",
        "print(\"=\"*60)\n",
        "print(full_accuracy_table)\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv('mistral_results_with_skills.csv', index=False)\n",
        "full_accuracy_table.to_csv('mistral_accuracy_analysis.csv', index=False)"
      ],
      "metadata": {
        "id": "Mkb2r4NEI3lA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2813b1a6-3139-4eb5-a13e-211f93b98525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Accuracy by Subdivision and Difficulty (% correct):\n",
            "============================================================\n",
            "Difficulty                                medium   Total\n",
            "Subdivision                                             \n",
            "Craft and Structure                       100.0%  100.0%\n",
            "Expression of Ideas                       100.0%  100.0%\n",
            "Information and Ideas                     100.0%  100.0%\n",
            "Standard English Conventions                0.0%    0.0%\n",
            "Total                         88.88888888888889%      0%\n",
            "\n",
            "============================================================\n",
            "Number of Questions by Subdivision and Difficulty:\n",
            "============================================================\n",
            "Difficulty                   medium Total\n",
            "Subdivision                              \n",
            "Craft and Structure               3     3\n",
            "Expression of Ideas               2     2\n",
            "Information and Ideas             3     3\n",
            "Standard English Conventions      1     1\n",
            "Total                             9     0\n",
            "\n",
            "============================================================\n",
            "Full Accuracy Analysis:\n",
            "============================================================\n",
            "           Category                          Name  total_questions  \\\n",
            "0        Difficulty                          easy                0   \n",
            "1        Difficulty                        medium                9   \n",
            "2        Difficulty                          hard                0   \n",
            "0       Subdivision  Standard English Conventions                1   \n",
            "1       Subdivision         Information and Ideas                3   \n",
            "2       Subdivision           Craft and Structure                3   \n",
            "3       Subdivision           Expression of Ideas                2   \n",
            "0  Type of Question                    boundaries                1   \n",
            "1  Type of Question    form, structure, and sense                0   \n",
            "2  Type of Question     central ideas and details                1   \n",
            "3  Type of Question                    inferences                1   \n",
            "4  Type of Question           command of evidence                1   \n",
            "5  Type of Question              words in context                1   \n",
            "6  Type of Question    text structure and purpose                1   \n",
            "7  Type of Question        cross-text connections                1   \n",
            "8  Type of Question          rhetorical synthesis                1   \n",
            "9  Type of Question                   transitions                1   \n",
            "\n",
            "   correct_answers  Accuracy (%)  average_variability  \n",
            "0                0      0.000000             0.000000  \n",
            "1                8     88.888889             1.111111  \n",
            "2                0      0.000000             0.000000  \n",
            "0                0      0.000000             2.000000  \n",
            "1                3    100.000000             1.000000  \n",
            "2                3    100.000000             1.000000  \n",
            "3                2    100.000000             1.000000  \n",
            "0                0      0.000000             2.000000  \n",
            "1                0      0.000000             0.000000  \n",
            "2                1    100.000000             1.000000  \n",
            "3                1    100.000000             1.000000  \n",
            "4                1    100.000000             1.000000  \n",
            "5                1    100.000000             1.000000  \n",
            "6                1    100.000000             1.000000  \n",
            "7                1    100.000000             1.000000  \n",
            "8                1    100.000000             1.000000  \n",
            "9                1    100.000000             1.000000  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-17cba4406d81>:169: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  merged[col] = merged[col+'_template'].where(pd.isna(merged[col]), merged[col])\n",
            "<ipython-input-11-17cba4406d81>:169: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  merged[col] = merged[col+'_template'].where(pd.isna(merged[col]), merged[col])\n",
            "<ipython-input-11-17cba4406d81>:169: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  merged[col] = merged[col+'_template'].where(pd.isna(merged[col]), merged[col])\n",
            "<ipython-input-11-17cba4406d81>:169: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  merged[col] = merged[col+'_template'].where(pd.isna(merged[col]), merged[col])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAT Question Evaluation System (Multi-Model)\n",
        "This script evaluates LLM performance on SAT questions through:  \n",
        "\n",
        "**Core Features**  \n",
        "- Cross-Model Comparison: Tests multiple LLMs on same question subset  \n",
        "- Difficulty Analysis: Evaluates easy/medium/hard questions equally (30 per level)  \n",
        "- Skill Breakdown: Analyzes 4 skill categories and 12 subtypes  \n",
        "- Low-Accuracy Tracking: Identifies top {N} hardest questions across all models  \n",
        "- Consistency Metrics: 3 attempts/question with variability scoring  \n",
        "\n",
        "**Key Processes**  \n",
        "1. Stratified Sampling: Balanced question selection by difficulty  \n",
        "2. Error-Resilient Evaluation: 3 retries per question with delay  \n",
        "3. Multi-Dimensional Tracking:  \n",
        "   - Accuracy (%) by difficulty/skill  \n",
        "   - Response consistency (1.0 = perfect stability)  \n",
        "   - Model processing speed  \n",
        "\n",
        "**Outputs Generated**  \n",
        "- Accuracy Tables: By difficulty/skill/subtype  \n",
        "- Variability Reports: Consistency metrics across attempts  \n",
        "- Time Metrics: Processing speed per model  \n",
        "- Low-Accuracy Export: CSV of hardest questions  \n",
        "- Raw Data: Full results in full_evaluation_results.csv  \n",
        "\n",
        "**Configuration Points**  \n",
        "- NUM_LOW_ACCURACY_QUESTIONS: Set number of challenging questions to track  \n",
        "- questions_per_difficulty: Questions per difficulty level (default:30)  \n",
        "- max_retries/delay: Error handling parameters  \n",
        "- Model List: Comment/uncomment models in evaluation pool  "
      ],
      "metadata": {
        "id": "90takoSiWvEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import numpy as np\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# ====== 1. INITIALIZATION ======\n",
        "models = [\n",
        "    (\"Claude 3.5 Haiku\", llm_Claude),\n",
        "    (\"ChatGPT 4.1 mini\", llm_ChatGPT),\n",
        "    (\"Gemini 2.0 Flash\", llm_Gemini),\n",
        "    (\"Llama 3.3 70B Instruct\", llm_Llama),\n",
        "    (\"Qwen3 235B-A22B\", llm_Qwen),\n",
        "    (\"DeepSeek V3\", llm_DeepSeek)\n",
        "]\n",
        "\n",
        "questions_per_difficulty = 30\n",
        "total_questions_per_model = questions_per_difficulty * 3\n",
        "max_retries = 3\n",
        "retry_delay = 5\n",
        "NUM_LOW_ACCURACY_QUESTIONS = 10\n",
        "\n",
        "skill_subdivisions = {\n",
        "    'Standard English Conventions': [\"boundaries\", \"form, structure, and sense\"],\n",
        "    'Information and Ideas': [\"central ideas and details\", \"inferences\", \"command of evidence\"],\n",
        "    'Craft and Structure': [\"words in context\", \"text structure and purpose\", \"cross-text connections\"],\n",
        "    'Expression of Ideas': [\"rhetorical synthesis\", \"transitions\"]\n",
        "}\n",
        "\n",
        "# ====== 2. DATA VERIFICATION ======\n",
        "required_columns = [\n",
        "    \"ID\", \"Question\", \"Correct Answer\", \"Difficulty\",\n",
        "    \"Type of Question\", \"Option A\", \"Option B\",\n",
        "    \"Option C\", \"Option D\"\n",
        "]\n",
        "missing = [col for col in required_columns if col not in sat_questions.columns]\n",
        "if missing:\n",
        "    raise KeyError(f\"Missing columns: {missing}\")\n",
        "\n",
        "for diff in ['easy', 'medium', 'hard']:\n",
        "    count = len(sat_questions[sat_questions['Difficulty'] == diff])\n",
        "    if count < questions_per_difficulty:\n",
        "        raise ValueError(f\"Need {questions_per_difficulty} {diff} questions, found {count}\")\n",
        "\n",
        "shared_questions = pd.DataFrame()\n",
        "for diff in ['easy', 'medium', 'hard']:\n",
        "    subset = sat_questions[sat_questions['Difficulty'] == diff].sample(n=questions_per_difficulty)\n",
        "    shared_questions = pd.concat([shared_questions, subset])\n",
        "\n",
        "if len(shared_questions) != total_questions_per_model:\n",
        "    raise ValueError(f\"Sampling failed. Expected {total_questions_per_model}, got {len(shared_questions)}\")\n",
        "\n",
        "# ====== 3. ANSWER PROCESSING FUNCTIONS ======\n",
        "def extract_answer(response: str) -> str:\n",
        "    \"\"\"Clean and extract first valid answer from model response\"\"\"\n",
        "    if hasattr(response, 'content'):\n",
        "        content = response.content\n",
        "    else:\n",
        "        content = str(response)\n",
        "\n",
        "    content = content.upper().strip()\n",
        "    standalone_match = re.search(r'\\b([A-D])\\b', content.split('.')[0])\n",
        "    if standalone_match:\n",
        "        return standalone_match.group(1)\n",
        "\n",
        "    for char in content:\n",
        "        if char in ('A', 'B', 'C', 'D'):\n",
        "            return char\n",
        "\n",
        "    return \"ERROR\"\n",
        "\n",
        "# ====== 4. EVALUATION PIPELINE ======\n",
        "all_results = []\n",
        "time_tracking = {}\n",
        "question_stats = {}\n",
        "\n",
        "for _, row in shared_questions.iterrows():\n",
        "    question_stats[row['ID']] = {\n",
        "        'Question': row['Question'],\n",
        "        'Correct Answer': row['Correct Answer'].strip().upper(),\n",
        "        'Difficulty': row['Difficulty'],\n",
        "        'Type of Question': row['Type of Question'],\n",
        "        'correct_attempts': 0,\n",
        "        'total_attempts': 0\n",
        "    }\n",
        "\n",
        "for model_name, model in models:\n",
        "    print(f\"\\nEvaluating {model_name}...\")\n",
        "    start_time = time.time()\n",
        "    model_results = []\n",
        "\n",
        "    for _, row in shared_questions.iterrows():\n",
        "        query = (\n",
        "            f\"Question: {row['Question']}\\n\"\n",
        "            f\"A) {row['Option A']}\\n\"\n",
        "            f\"B) {row['Option B']}\\n\"\n",
        "            f\"C) {row['Option C']}\\n\"\n",
        "            f\"D) {row['Option D']}\"\n",
        "        )\n",
        "        correct_answer = row['Correct Answer'].strip().upper()\n",
        "        responses = []\n",
        "        retry_count = 0\n",
        "\n",
        "        for _ in range(3):\n",
        "            current_retry = 0\n",
        "            while current_retry < max_retries:\n",
        "                try:\n",
        "                    result = model.invoke(prompt.format_prompt(input=query))\n",
        "                    cleaned_response = extract_answer(result)\n",
        "                    responses.append(cleaned_response)\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    current_retry += 1\n",
        "                    if current_retry >= max_retries:\n",
        "                        responses.append(\"ERROR\")\n",
        "                        print(f\"Failed processing question: {e}\")\n",
        "                    else:\n",
        "                        time.sleep(retry_delay)\n",
        "\n",
        "        valid_responses = [r for r in responses if r != 'ERROR']\n",
        "        if not valid_responses:\n",
        "            mode_response = 'ERROR'\n",
        "        else:\n",
        "            counts = Counter(valid_responses)\n",
        "            max_count = max(counts.values())\n",
        "            modes = [k for k, v in counts.items() if v == max_count]\n",
        "            mode_response = modes[0]\n",
        "\n",
        "        q_id = row['ID']\n",
        "        question_stats[q_id]['total_attempts'] += 1\n",
        "        if mode_response == correct_answer:\n",
        "            question_stats[q_id]['correct_attempts'] += 1\n",
        "\n",
        "        # Store all three responses for variability calculation\n",
        "        model_results.append({\n",
        "            \"Question_ID\": q_id,\n",
        "            \"Model\": model_name,\n",
        "            \"Difficulty\": row['Difficulty'],\n",
        "            \"Skill Type\": row['Type of Question'],\n",
        "            \"Response\": mode_response,\n",
        "            \"Correct Answer\": correct_answer,\n",
        "            \"All_Responses\": responses  # Store all responses\n",
        "        })\n",
        "\n",
        "    time_tracking[model_name] = round(time.time() - start_time, 2)\n",
        "    all_results.extend(model_results)\n",
        "    print(f\"Completed {model_name} in {time_tracking[model_name]}s\")\n",
        "\n",
        "# ====== 5. ANALYSIS PIPELINE ======\n",
        "stats_df = pd.DataFrame.from_dict(question_stats, orient='index').reset_index()\n",
        "stats_df = stats_df.rename(columns={'index': 'Question_ID'})\n",
        "stats_df['Accuracy (%)'] = (stats_df['correct_attempts'] / stats_df['total_attempts']) * 100\n",
        "\n",
        "low_accuracy_df = stats_df.sort_values('Accuracy (%)').head(NUM_LOW_ACCURACY_QUESTIONS)\n",
        "low_accuracy_df = low_accuracy_df[[\n",
        "    'Question_ID',\n",
        "    'Difficulty',\n",
        "    'Type of Question',\n",
        "    'correct_attempts',\n",
        "    'total_attempts',\n",
        "    'Accuracy (%)',\n",
        "    'Question'\n",
        "]].rename(columns={\n",
        "    'correct_attempts': 'Correct Answers',\n",
        "    'total_attempts': 'Total Answers'\n",
        "})\n",
        "\n",
        "print(f\"\\n{'#'*40}\")\n",
        "print(f\"{NUM_LOW_ACCURACY_QUESTIONS} Lowest Accuracy Questions\")\n",
        "print(low_accuracy_df.round(1).to_string(index=False))\n",
        "low_accuracy_df.to_csv('low_accuracy_questions.csv', index=False)\n",
        "\n",
        "def full_analysis(model_df):\n",
        "    skill_to_subdivision = {}\n",
        "    for subdivision, skills in skill_subdivisions.items():\n",
        "        for skill in skills:\n",
        "            skill_to_subdivision[skill] = subdivision\n",
        "\n",
        "    model_df = model_df.copy()\n",
        "    model_df['Subdivision'] = model_df['Skill Type'].map(skill_to_subdivision)\n",
        "    model_df['is_correct'] = np.where(\n",
        "        model_df['Response'] == model_df['Correct Answer'],\n",
        "        True,\n",
        "        False\n",
        "    )\n",
        "\n",
        "    # Calculate per-question variability\n",
        "    def calculate_variability(responses):\n",
        "        valid = [r for r in responses if r != 'ERROR']\n",
        "        return len(set(valid)) if valid else 0\n",
        "\n",
        "    model_df['variability'] = model_df['All_Responses'].apply(calculate_variability)\n",
        "\n",
        "    analysis = []\n",
        "    categories = {\n",
        "        'Difficulty': ['easy', 'medium', 'hard'],\n",
        "        'Subdivision': list(skill_subdivisions.keys()),\n",
        "        'Skill Type': [skill for sublist in skill_subdivisions.values() for skill in sublist]\n",
        "    }\n",
        "\n",
        "    for cat_type, cat_list in categories.items():\n",
        "        temp_df = pd.DataFrame({cat_type: cat_list})\n",
        "        grouped = model_df.groupby(cat_type, observed=True).agg(\n",
        "            total=('is_correct', 'size'),\n",
        "            correct=('is_correct', 'sum'),\n",
        "            avg_variability=('variability', 'mean')\n",
        "        ).reset_index()\n",
        "\n",
        "        merged = temp_df.merge(grouped, how='left', on=cat_type).fillna(0)\n",
        "        merged['Category'] = cat_type\n",
        "\n",
        "        if cat_type == 'Difficulty':\n",
        "            total_row = pd.DataFrame({\n",
        "                cat_type: ['Total'],\n",
        "                'total': [merged['total'].sum()],\n",
        "                'correct': [merged['correct'].sum()],\n",
        "                'avg_variability': [model_df['variability'].mean()],\n",
        "                'Category': ['Difficulty']\n",
        "            })\n",
        "            merged = pd.concat([merged, total_row], ignore_index=True)\n",
        "\n",
        "        analysis.append(merged.rename(columns={cat_type: 'Name'}))\n",
        "\n",
        "    full = pd.concat(analysis)\n",
        "    full['Accuracy (%)'] = (full['correct'] / full['total'].replace(0, 1)) * 100\n",
        "    return full[['Category', 'Name', 'total', 'correct', 'Accuracy (%)', 'avg_variability']]\n",
        "\n",
        "# Generate reports\n",
        "results_df = pd.DataFrame(all_results)\n",
        "for model in results_df['Model'].unique():\n",
        "    analysis = full_analysis(results_df[results_df['Model'] == model])\n",
        "    print(f\"\\n{'#'*40}\\nFull Analysis for {model}\\n{'#'*40}\")\n",
        "    print(analysis.to_string(\n",
        "        formatters={\n",
        "            'Accuracy (%)': '{:.1f}%'.format,\n",
        "            'avg_variability': '{:.2f}'.format\n",
        "        },\n",
        "        index=False\n",
        "    ))\n",
        "\n",
        "results_df.to_csv('full_evaluation_results.csv', index=False)\n",
        "print(\"\\nEvaluation complete! Results saved to full_evaluation_results.csv\")"
      ],
      "metadata": {
        "id": "A7vw1G7OX-H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad5efc0-6661-4283-cc50-719ef26c3068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Claude 3.5 Haiku...\n",
            "Completed Claude 3.5 Haiku in 319.5s\n",
            "\n",
            "Evaluating ChatGPT 4.1 mini...\n",
            "Completed ChatGPT 4.1 mini in 184.5s\n",
            "\n",
            "Evaluating Gemini 2.0 Flash...\n",
            "Completed Gemini 2.0 Flash in 94.51s\n",
            "\n",
            "Evaluating Llama 3.3 70B Instruct...\n",
            "Completed Llama 3.3 70B Instruct in 843.92s\n",
            "\n",
            "Evaluating Qwen3 235B-A22B...\n",
            "Completed Qwen3 235B-A22B in 2750.02s\n",
            "\n",
            "Evaluating DeepSeek V3...\n",
            "Completed DeepSeek V3 in 221.84s\n",
            "\n",
            "########################################\n",
            "10 Lowest Accuracy Questions\n",
            "Question_ID Difficulty           Type of Question  Correct Answers  Total Answers  Accuracy (%)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Question\n",
            "   eb95235b       hard                 boundaries                0              6           0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                          The Limón technique, developed by Mexican-born dancer and choreographer Jose Limón, is known for its emphasis on breath control and its interplay of weight and ______ dancers may explore, for example, the moment of mid-air suspension at the top of a jump. Which choice completes the text so that it conforms to the conventions of Standard English?\n",
            "   a2816c7f       hard form, structure, and sense                0              6           0.0                                                                                                                                                                                                                                                                                                                                                                                                                                             American abstract artist Richard ______ his installations to make passersby keenly aware of how one's movements are affected by the physical features of one's environment, assembles large-scale steel plates into sculptures that dominate the outdoor spaces they occupy. Which choice completes the text so that it conforms to the conventions of Standard English?\n",
            "   702eb7e3       hard        command of evidence                0              6           0.0                                                             High levels of public uncertainty about which economic policies a country will adopt can make planning difficult for businesses, but measures of such uncertainty have not tended to be very detailed. Recently, however, economist Sandile Hlatshwayo analyzed trends in news reports to derive measures not only for general economic policy uncertainty but also for uncertainty related to specific areas of economic policy, like tax or trade policy. One revelation of her work is that a general measure may not fully reflect uncertainty about specific areas of policy, as in the case of the United Kingdom, where general economic policy uncertainty _____ Which choice most effectively uses data from the graph to illustrate the claim?\n",
            "   74ce2f05     medium                 boundaries                1              6          16.7                                                                                                                                                                                                                                                                                                                                                   A study led by scientist Rebecca Kirby at the University of Wisconsin–Madison found that black bears that eat human food before hibernation have increased levels of a rare carbon isotope, ______ due to the higher \\( ^{13}C \\) levels in corn and cane sugar. Bears with these elevated levels were also found to have much shorter hibernation periods on average. Which choice completes the text so that it conforms to the conventions of Standard English?\n",
            "   89fbc3eb     medium                 boundaries                1              6          16.7                                                                                                                                                                                                                                                                                                                                                                                    The Mission 66 initiative, which was approved by Congress in 1956, represented a major investment in the infrastructure of overburdened national ______ it prioritized physical improvements to the parks’ roads, utilities, employee housing, and visitor facilities while also establishing educational programming for the public. Which choice completes the text so that it conforms to the conventions of Standard English?\n",
            "   e3edc138       hard                transitions                1              6          16.7                                                                                                                                                                                                                                                                                                                                                                                 In a heated debate in biogeography, the field is divided between dispersalists and vicariancists. ______ there are those who argue that dispersal is the most crucial determining factor in a species’ distribution, and those who insist that vicariance (separation due to geographic barriers) is. Biogeographer Isabel Sanmartín counts herself among neither. Which choice completes the text with the most logical transition?\n",
            "   adf210e7       hard                 boundaries                2              6          33.3                                                                                                                                                                                                                                                                                                                                                                                            The haiku-like poems of Tomas Tranströmer, which present nature- and dream-influenced images in crisp, spare language, have earned the Swedish poet praise from leading contemporary ______ them Nigerian American essayist and novelist Teju Cole, who has written that Tranströmer’s works 'contain a luminous simplicity.' Which choice completes the text so that it conforms to the conventions of Standard English?\n",
            "   a7c85001       easy                 boundaries                2              6          33.3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Researchers Amit Kumar and Nicholas Epley investigated how _____ In a series of experiments conducted in 2022, they found that people performing small acts of kindness underestimated the positive effect their actions had on others. Which choice completes the text so that it conforms to the conventions of Standard English?\n",
            "   b46e0c8a     medium       rhetorical synthesis                3              6          50.0 While researching a topic, a student has taken the following notes: Organisms release cellular material into their environment by shedding substances such as hair or skin. The DNA in these substances is known as environmental DNA, or eDNA. Researchers collect and analyze eDNA to detect the presence of species that are difficult to observe. Geneticist Sara Oyler-McCance’s research team analyzed eDNA in water samples from the Florida Everglades to detect invasive constrictor snake species in the area. The study determined a 91% probability of detecting Burmese python eDNA in a given location. The student wants to present the study to an audience already familiar with environmental DNA. Which choice most effectively uses relevant information from the notes to accomplish this goal?\n",
            "   1ee7b429     medium form, structure, and sense                3              6          50.0                                                                                                                                                                                                                                                                                                                                                                                                                               Bonnie Buratti of NASA’s Jet Propulsion Laboratory ____ data about Saturn’s rings collected by the Cassini spacecraft when she made an interesting discovery: the tiny moons embedded between and within Saturn’s rings are shaped by the buildup of ring material on the moons’ surfaces. Which choice completes the text so that it conforms to the conventions of Standard English?\n",
            "\n",
            "########################################\n",
            "Full Analysis for Claude 3.5 Haiku\n",
            "########################################\n",
            "   Category                         Name  total  correct Accuracy (%) avg_variability\n",
            " Difficulty                         easy     30       30       100.0%            1.03\n",
            " Difficulty                       medium     30       21        70.0%            1.23\n",
            " Difficulty                         hard     30       19        63.3%            1.20\n",
            " Difficulty                        Total     90       70        77.8%            1.16\n",
            "Subdivision Standard English Conventions     18        9        50.0%            1.33\n",
            "Subdivision        Information and Ideas     27       26        96.3%            1.07\n",
            "Subdivision          Craft and Structure     27       24        88.9%            1.11\n",
            "Subdivision          Expression of Ideas     18       11        61.1%            1.17\n",
            " Skill Type                   boundaries      9        4        44.4%            1.44\n",
            " Skill Type   form, structure, and sense      9        5        55.6%            1.22\n",
            " Skill Type    central ideas and details      9        9       100.0%            1.00\n",
            " Skill Type                   inferences      9        9       100.0%            1.00\n",
            " Skill Type          command of evidence      9        8        88.9%            1.22\n",
            " Skill Type             words in context      9        8        88.9%            1.11\n",
            " Skill Type   text structure and purpose      9        8        88.9%            1.00\n",
            " Skill Type       cross-text connections      9        8        88.9%            1.22\n",
            " Skill Type         rhetorical synthesis      9        6        66.7%            1.11\n",
            " Skill Type                  transitions      9        5        55.6%            1.22\n",
            "\n",
            "########################################\n",
            "Full Analysis for ChatGPT 4.1 mini\n",
            "########################################\n",
            "   Category                         Name  total  correct Accuracy (%) avg_variability\n",
            " Difficulty                         easy     30       29        96.7%            1.03\n",
            " Difficulty                       medium     30       28        93.3%            1.07\n",
            " Difficulty                         hard     30       25        83.3%            1.10\n",
            " Difficulty                        Total     90       82        91.1%            1.07\n",
            "Subdivision Standard English Conventions     18       14        77.8%            1.22\n",
            "Subdivision        Information and Ideas     27       26        96.3%            1.00\n",
            "Subdivision          Craft and Structure     27       27       100.0%            1.04\n",
            "Subdivision          Expression of Ideas     18       15        83.3%            1.06\n",
            " Skill Type                   boundaries      9        6        66.7%            1.33\n",
            " Skill Type   form, structure, and sense      9        8        88.9%            1.11\n",
            " Skill Type    central ideas and details      9        9       100.0%            1.00\n",
            " Skill Type                   inferences      9        9       100.0%            1.00\n",
            " Skill Type          command of evidence      9        8        88.9%            1.00\n",
            " Skill Type             words in context      9        9       100.0%            1.00\n",
            " Skill Type   text structure and purpose      9        9       100.0%            1.11\n",
            " Skill Type       cross-text connections      9        9       100.0%            1.00\n",
            " Skill Type         rhetorical synthesis      9        8        88.9%            1.00\n",
            " Skill Type                  transitions      9        7        77.8%            1.11\n",
            "\n",
            "########################################\n",
            "Full Analysis for Gemini 2.0 Flash\n",
            "########################################\n",
            "   Category                         Name  total  correct Accuracy (%) avg_variability\n",
            " Difficulty                         easy     30       29        96.7%            1.00\n",
            " Difficulty                       medium     30       26        86.7%            1.03\n",
            " Difficulty                         hard     30       25        83.3%            1.00\n",
            " Difficulty                        Total     90       80        88.9%            1.01\n",
            "Subdivision Standard English Conventions     18       11        61.1%            1.06\n",
            "Subdivision        Information and Ideas     27       26        96.3%            1.00\n",
            "Subdivision          Craft and Structure     27       27       100.0%            1.00\n",
            "Subdivision          Expression of Ideas     18       16        88.9%            1.00\n",
            " Skill Type                   boundaries      9        4        44.4%            1.00\n",
            " Skill Type   form, structure, and sense      9        7        77.8%            1.11\n",
            " Skill Type    central ideas and details      9        9       100.0%            1.00\n",
            " Skill Type                   inferences      9        9       100.0%            1.00\n",
            " Skill Type          command of evidence      9        8        88.9%            1.00\n",
            " Skill Type             words in context      9        9       100.0%            1.00\n",
            " Skill Type   text structure and purpose      9        9       100.0%            1.00\n",
            " Skill Type       cross-text connections      9        9       100.0%            1.00\n",
            " Skill Type         rhetorical synthesis      9        7        77.8%            1.00\n",
            " Skill Type                  transitions      9        9       100.0%            1.00\n",
            "\n",
            "########################################\n",
            "Full Analysis for Llama 3.3 70B Instruct\n",
            "########################################\n",
            "   Category                         Name  total  correct Accuracy (%) avg_variability\n",
            " Difficulty                         easy     30       28        93.3%            1.00\n",
            " Difficulty                       medium     30       27        90.0%            1.00\n",
            " Difficulty                         hard     30       24        80.0%            1.00\n",
            " Difficulty                        Total     90       79        87.8%            1.00\n",
            "Subdivision Standard English Conventions     18       11        61.1%            1.00\n",
            "Subdivision        Information and Ideas     27       25        92.6%            1.00\n",
            "Subdivision          Craft and Structure     27       27       100.0%            1.00\n",
            "Subdivision          Expression of Ideas     18       16        88.9%            1.00\n",
            " Skill Type                   boundaries      9        4        44.4%            1.00\n",
            " Skill Type   form, structure, and sense      9        7        77.8%            1.00\n",
            " Skill Type    central ideas and details      9        9       100.0%            1.00\n",
            " Skill Type                   inferences      9        9       100.0%            1.00\n",
            " Skill Type          command of evidence      9        7        77.8%            1.00\n",
            " Skill Type             words in context      9        9       100.0%            1.00\n",
            " Skill Type   text structure and purpose      9        9       100.0%            1.00\n",
            " Skill Type       cross-text connections      9        9       100.0%            1.00\n",
            " Skill Type         rhetorical synthesis      9        9       100.0%            1.00\n",
            " Skill Type                  transitions      9        7        77.8%            1.00\n",
            "\n",
            "########################################\n",
            "Full Analysis for Qwen3 235B-A22B\n",
            "########################################\n",
            "   Category                         Name  total  correct Accuracy (%) avg_variability\n",
            " Difficulty                         easy     30        9        30.0%            1.00\n",
            " Difficulty                       medium     30       10        33.3%            1.00\n",
            " Difficulty                         hard     30       10        33.3%            1.00\n",
            " Difficulty                        Total     90       29        32.2%            1.00\n",
            "Subdivision Standard English Conventions     18        3        16.7%            1.00\n",
            "Subdivision        Information and Ideas     27        9        33.3%            1.00\n",
            "Subdivision          Craft and Structure     27        9        33.3%            1.00\n",
            "Subdivision          Expression of Ideas     18        8        44.4%            1.00\n",
            " Skill Type                   boundaries      9        0         0.0%            1.00\n",
            " Skill Type   form, structure, and sense      9        3        33.3%            1.00\n",
            " Skill Type    central ideas and details      9        2        22.2%            1.00\n",
            " Skill Type                   inferences      9        5        55.6%            1.00\n",
            " Skill Type          command of evidence      9        2        22.2%            1.00\n",
            " Skill Type             words in context      9        3        33.3%            1.00\n",
            " Skill Type   text structure and purpose      9        3        33.3%            1.00\n",
            " Skill Type       cross-text connections      9        3        33.3%            1.00\n",
            " Skill Type         rhetorical synthesis      9        7        77.8%            1.00\n",
            " Skill Type                  transitions      9        1        11.1%            1.00\n",
            "\n",
            "########################################\n",
            "Full Analysis for DeepSeek V3\n",
            "########################################\n",
            "   Category                         Name  total  correct Accuracy (%) avg_variability\n",
            " Difficulty                         easy     30       30       100.0%            1.00\n",
            " Difficulty                       medium     30       28        93.3%            1.13\n",
            " Difficulty                         hard     30       24        80.0%            1.17\n",
            " Difficulty                        Total     90       82        91.1%            1.10\n",
            "Subdivision Standard English Conventions     18       13        72.2%            1.39\n",
            "Subdivision        Information and Ideas     27       26        96.3%            1.00\n",
            "Subdivision          Craft and Structure     27       27       100.0%            1.00\n",
            "Subdivision          Expression of Ideas     18       16        88.9%            1.11\n",
            " Skill Type                   boundaries      9        5        55.6%            1.56\n",
            " Skill Type   form, structure, and sense      9        8        88.9%            1.22\n",
            " Skill Type    central ideas and details      9        9       100.0%            1.00\n",
            " Skill Type                   inferences      9        9       100.0%            1.00\n",
            " Skill Type          command of evidence      9        8        88.9%            1.00\n",
            " Skill Type             words in context      9        9       100.0%            1.00\n",
            " Skill Type   text structure and purpose      9        9       100.0%            1.00\n",
            " Skill Type       cross-text connections      9        9       100.0%            1.00\n",
            " Skill Type         rhetorical synthesis      9        8        88.9%            1.11\n",
            " Skill Type                  transitions      9        8        88.9%            1.11\n",
            "\n",
            "Evaluation complete! Results saved to full_evaluation_results.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}